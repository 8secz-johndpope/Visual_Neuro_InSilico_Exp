{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BigGAN Hessian Computation\n",
    "This repo tries to prove whether we could compute hessian of BigGAN (activation or image similarity) by forward finite difference method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_pretrained_biggan import BigGAN, truncated_noise_sample\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from hessian_eigenthings.power_iter import Operator, deflated_power_iteration\n",
    "from hessian_eigenthings.lanczos import lanczos\n",
    "from lanczos_generalized import lanczos_generalized\n",
    "from GAN_hvp_operator import GANHVPOperator, GANForwardHVPOperator, compute_hessian_eigenthings\n",
    "#%\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from time import time\n",
    "from os.path import join\n",
    "from imageio import imwrite\n",
    "from build_montages import build_montages, color_framed_montages\n",
    "import torchvision.models as tv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BGAN = BigGAN.from_pretrained(\"biggan-deep-256\")\n",
    "#%\n",
    "for param in BGAN.parameters():\n",
    "    param.requires_grad_(False)\n",
    "BGAN.cuda()\n",
    "#%\n",
    "alexnet = tv.alexnet(pretrained=True).cuda()\n",
    "alexnet.eval() # this is important or there will be trial to trial variability due to DropOut\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad_(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%0\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from FeatLinModel import FeatLinModel, get_model_layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize, Compose\n",
    "RGB_mean = torch.tensor([0.485, 0.456, 0.406]).view(1,-1,1,1).cuda()\n",
    "RGB_std  = torch.tensor([0.229, 0.224, 0.225]).view(1,-1,1,1).cuda()\n",
    "preprocess = Compose([lambda img: (F.interpolate(img, (224, 224), mode='bilinear', align_corners=True) - RGB_mean) / RGB_std])\n",
    "preprocess_resize = Compose([lambda img: F.interpolate(img, (224, 224), mode='bilinear', align_corners=True) ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "feat = torch.randn(256).cuda().requires_grad_(True)\n",
    "img = BGAN.generator(feat, 0.7)\n",
    "obj = img.mean()\n",
    "# obj.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from hessian import hessian\n",
    "H = hessian(obj, feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "eigval, eigvec = np.linalg.eigh(H.cpu().numpy())\n",
    "plt.plot(sorted(eigval))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objective = FeatLinModel(alexnet, layername=\"features_10\", type=\"neuron\", chan=10, pos=(7, 7))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feat = torch.randn(256).cuda().requires_grad_(True)\n",
    "act = objective(preprocess(BGAN.generator(feat, 0.7)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "from hessian import hessian\n",
    "H_act = hessian(act, feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% < 60 sec for this computation\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "eigval, eigvec = np.linalg.eigh(H_act.cpu().numpy())\n",
    "plt.plot(sorted(eigval))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(eigval, bins=30, log=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del objective"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above, we have proved that we can compute hessian for BigGAN by backprop 2 times and we can find its spectrum. \n",
    "\n",
    "Next, I'd like to examine its spectrum in noise space and code space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onehot = torch.zeros(1, 1000).requires_grad_(False)\n",
    "onehot[0, 1] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec = BGAN.embeddings(onehot.cuda())\n",
    "noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6))\n",
    "#%\n",
    "img = BGAN.generator(torch.cat((noisevec.cuda(), classvec, ), dim=1), 0.6)\n",
    "#%\n",
    "plt.imshow((img.cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec = BGAN.embeddings(onehot.cuda())\n",
    "noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6)).cuda()\n",
    "classvec.requires_grad_(True)\n",
    "img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "act = alexnet(preprocess_resize(img))[0,1]\n",
    "plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "H_class = hessian(act, classvec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "act.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onehot = torch.zeros(1, 1000).requires_grad_(False)\n",
    "onehot[0, 1] = 1\n",
    "classvec = BGAN.embeddings(onehot.cuda())\n",
    "noisevec = torch.from_numpy(truncated_noise_sample(1, 128, 0.6)).cuda()\n",
    "alexnet.train(True)\n",
    "classvec.requires_grad_(True)\n",
    "print(classvec.norm())\n",
    "optimizer = optim.Adam([classvec], lr=1.5E-3)\n",
    "for step in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "    obj =  - alexnet(preprocess_resize(img))[0,1]\n",
    "    obj.backward()\n",
    "    optimizer.step()\n",
    "    if np.mod((step + 1), 10) == 0:\n",
    "        print(\"step %d: %.2f\"%(step, obj.item()))\n",
    "        plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "print(classvec.norm())\n",
    "img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "act = alexnet(preprocess_resize(img))[0,1]\n",
    "plt.imshow((img.detach().cpu().permute(2,3,1,0).squeeze() + 1.0) / 2.0)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "alexnet.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec.grad.norm() / classvec.norm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classvec.norm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "classvec.requires_grad_(True)\n",
    "noisevec.requires_grad_(False)\n",
    "img = BGAN.generator(torch.cat((noisevec, classvec, ), dim=1), 0.6)\n",
    "act =  - alexnet(preprocess_resize(img))[0,1]\n",
    "H_act_class = get_full_hessian(act, classvec)\n",
    "#%\n",
    "eigval_class, eigvec_class = np.linalg.eigh(H_act_class)\n",
    "plt.plot(sorted(eigval_class))\n",
    "plt.show()\n",
    "plt.hist(eigval_class, bins=30, log=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "H_act_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from hessian_eigenthings.utils import progress_bar\n",
    "def get_full_hessian(loss, param):\n",
    "    # from https://discuss.pytorch.org/t/compute-the-hessian-matrix-of-a-network/15270/3\n",
    "    # modified from hessian_eigenthings repo. api follows hessian.hessian\n",
    "    hessian_size = param.numel()\n",
    "    hessian = torch.zeros(hessian_size, hessian_size)\n",
    "    loss_grad = torch.autograd.grad(loss, param, create_graph=True, retain_graph=True, only_inputs=True)[0].view(-1)\n",
    "    for idx in range(hessian_size):\n",
    "        clear_output(wait = True)\n",
    "        progress_bar(\n",
    "            idx, hessian_size, \"full hessian columns: %d of %d\" % (idx, hessian_size)\n",
    "        )\n",
    "        grad2rd = torch.autograd.grad(loss_grad[idx], param, create_graph=False, retain_graph=True, only_inputs=True)\n",
    "        hessian[idx] = grad2rd[0].view(-1)\n",
    "    return hessian.cpu().data.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tuning_plot_BigGAN(G, preprocess, objective, feat, eigvals, eigvects, space=\"class\",\n",
    "        eig_id_arr=(0, 1, 5, 10, 15, 20, 40, 60, 80,99, 120, 127),\n",
    "        save_indiv=False, save_row=False, summary_dir=\"\", veclabel=\"eig\", titlestr=\"\", lim=(-1, 1), ticks=21, \n",
    "        pad=24, cmap=plt.cm.viridis, RND=None):\n",
    "    if RND is None: RND = np.random.randint(100)\n",
    "    vec_norm = feat.norm().item()\n",
    "    \n",
    "    if space == \"class\":\n",
    "        step = 2 / (ticks - 1)\n",
    "        step_arr = torch.linspace(lim[0], lim[1], ticks)\n",
    "        ref_vect = feat.detach().clone()\n",
    "    elif space == \"noise\":\n",
    "        theta_arr_deg =  np.linspace(-90, 90, ticks) # np.arange(-5, 6)\n",
    "        theta_arr = theta_arr_deg / 180 * np.pi\n",
    "        ref_vect = (feat / vec_norm).cpu().numpy()\n",
    "    img_list_all = []\n",
    "    scores_col = [] # array version of scores\n",
    "    scores_all = [] # list version of scores\n",
    "    # eig_id_arr = [0, 1, 5, 10, 15, 20, 40, 60, 80,99,150,200,250,299,450]\n",
    "    batch = 6\n",
    "    for eig_id in eig_id_arr: #,600,799]:\n",
    "        # eig_id = 0\n",
    "        perturb_vect = eigvects[eig_id,:]  # PC_vectors[1,:]\n",
    "        if space == \"class\":\n",
    "            perturb_vecs = step_arr.unsqueeze(1) @ torch.from_numpy(perturb_vect).unsqueeze(0)\n",
    "            perturb_vecs = torch.cat((torch.zeros_like(perturb_vecs), perturb_vecs), dim=1)\n",
    "            codes_arc = perturb_vecs.cuda() + ref_vect.cuda()\n",
    "            codes_arc.requires_grad_(False)\n",
    "            csr = 0\n",
    "            with torch.no_grad():\n",
    "                img_batchs = []\n",
    "                while csr < codes_arc.size(0):\n",
    "                    csr_end = min(csr + batch, codes_arc.size(0))\n",
    "                    imgs = G.generator(codes_arc[csr:csr_end, :], 0.6)\n",
    "                    img_batchs.append(imgs)\n",
    "                    csr = csr_end\n",
    "                imgs = torch.cat(tuple(img_batchs), dim=0)\n",
    "        elif space == \"noise\":\n",
    "            codes_arc = np.array([np.cos(theta_arr),\n",
    "                              np.sin(theta_arr) ]).T @ np.array([ref_vect, perturb_vect])\n",
    "            norms = np.linalg.norm(codes_arc, axis=1)\n",
    "            codes_arc = codes_arc / norms[:, np.newaxis] * vec_norm\n",
    "            imgs = G.visualize(torch.from_numpy(codes_arc).float().cuda())\n",
    "        scores = - objective(preprocess(imgs), scaler=False)\n",
    "        scores_col.append(scores.cpu().numpy())\n",
    "        scores_all.extend(scores.cpu().squeeze().tolist())\n",
    "        npimgs = np.clip((imgs.detach().cpu().permute([2, 3, 1, 0]).numpy() + 1) / 2, 0, 1)\n",
    "\n",
    "        if save_indiv:\n",
    "            for i in range(npimgs.shape[3]):\n",
    "                angle = theta_arr_deg[i]\n",
    "                imwrite(join(newimg_dir, \"norm%d_%s%d_ang%d.jpg\" % (vec_norm, veclabel, eig_id, angle)), npimgs[:, :, :, i])\n",
    "\n",
    "        img_list = [npimgs[:, :, :, i] for i in range(npimgs.shape[3])]\n",
    "        img_list_all.extend(img_list)\n",
    "        if save_row:\n",
    "            mtg1 = build_montages(img_list, [256, 256], [ticks, 1])[0]\n",
    "            imwrite(join(summary_dir, \"norm%d_%s_%d.jpg\" % (vec_norm, veclabel, eig_id)), mtg1)\n",
    "    mtg_all = build_montages(img_list_all, [256, 256], [ticks, int(len(img_list_all) // ticks)])[0]\n",
    "    imwrite(join(summary_dir, \"norm%d_%s_%d.jpg\" % (vec_norm, veclabel, RND)), mtg_all)\n",
    "    print(\"Write to \", join(summary_dir, \"norm%d_%s_%d.jpg\" % (vec_norm, veclabel, RND)))\n",
    "\n",
    "    mtg_frm = color_framed_montages(img_list_all, [256, 256], [ticks, int(len(img_list_all) // ticks)], scores_all, pad=pad, cmap=cmap)[0]\n",
    "    imwrite(join(summary_dir, \"norm%d_%s_framed_%d.jpg\" % (vec_norm, veclabel, RND)), mtg_frm)\n",
    "    print(\"Write to \", join(summary_dir, \"norm%d_%s_framed_%d.jpg\" % (vec_norm, veclabel, RND)))\n",
    "    \n",
    "    scores_col = np.array(scores_col)\n",
    "    plt.figure(figsize=[8,10],dpi=100)\n",
    "    plt.matshow(scores_col)\n",
    "    plt.axis('image')\n",
    "    plt.title(\"Neural Tuning Towards Different Eigen Vectors of Activation\")\n",
    "    plt.xlabel(\"Angle\")\n",
    "    plt.ylabel(\"Eigen Vector #\")\n",
    "    eiglabel = [\"%d %.3f\"%(id,eig) for id, eig in zip(eig_id_arr, eigvals[list(eig_id_arr)])]\n",
    "    plt.yticks(range(len(eig_id_arr)), eiglabel) # eig_id_arr\n",
    "    plt.ylim(top=-0.5, bottom=len(eig_id_arr) - 0.5)\n",
    "    plt.colorbar()\n",
    "    plt.suptitle(titlestr)\n",
    "    plt.savefig(join(summary_dir, \"norm%d_%s_score_mat_%02d.jpg\" % (vec_norm, veclabel, RND)) , dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Write to \", join(summary_dir, \"norm%d_%s_score_mat_%02d.jpg\" % (vec_norm, veclabel, RND)) )\n",
    "    return img_list, scores_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "savedir = r\"E:\\OneDrive - Washington University in St. Louis\\HessTune\\BigGAN\"\n",
    "# objective = lambda img, scaler: alexnet(img)[:,1].mean() if scaler else alexnet(img)[:,1]\n",
    "alexnet.eval()\n",
    "objective = FeatLinModel(alexnet, layername=\"classifier_6\", type=\"neuron\", chan=1, pos=(1,1))\n",
    "ref_vect = torch.cat((noisevec.detach(), classvec.detach(), ), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_class, eigvec_class, eig_id_arr=(1,2,3,4,5,6,7,8,9,10, 20, 30, 40, 50, 60, 70, 80, 100, 110, 120), \n",
    "            space=\"class\", ticks=11, lim=(-2,2), summary_dir=savedir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(eigval_class)\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_class, eigvec_class, eig_id_arr=sort_idx[-15:], \n",
    "            space=\"class\", ticks=15, lim=(-2,2), summary_dir=savedir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(np.abs(eigval_class))\n",
    "img_list, scores_col = tuning_plot_BigGAN(BGAN, preprocess_resize, objective, \n",
    "            ref_vect, eigval_class, eigvec_class, eig_id_arr=sort_idx[:15], \n",
    "            space=\"class\", ticks=15, lim=(-2,2), summary_dir=savedir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del BGAN, alexnet, objective\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del act\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}